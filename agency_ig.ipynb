{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -r installments.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and Install SpaCy's LLM\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImpmRruOTaaR",
        "outputId": "a29f117e-b273-42b7-9bfe-a6ce06fc352a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "import ftfy\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from captum.attr import IntegratedGradients\n",
        "import spacy\n",
        "from IPython.display import HTML\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    # To use GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('GPU is:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M7ar4TtZTu5h"
      },
      "outputs": [],
      "source": [
        "class AgencyIG:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the model, tokenizer, and SpaCy NLP pipeline.\"\"\"\n",
        "        self.model_name = \"EnchantedStardust/bertagent-best\"\n",
        "        self.revision = \"5bae55efbd95dd51759d275410cea36c81109227\"\n",
        "\n",
        "        # Initialize tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.model_name, do_lower_case=True, revision=self.revision\n",
        "        )\n",
        "\n",
        "        # Initialize model\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.model_name, num_labels=1, revision=self.revision\n",
        "        ).to(device)\n",
        "\n",
        "        # Initialize SpaCy\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def extract_ig(self, sentences):\n",
        "        \"\"\"Extract integrated gradients for a list of sentences.\"\"\"\n",
        "        # Clean sentences\n",
        "        cleaned_sentences = self._clean_sentences(sentences)\n",
        "\n",
        "        # Tokenize sentences\n",
        "        tokenized = self.tokenizer(\n",
        "            cleaned_sentences,\n",
        "            add_special_tokens=True,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=False,\n",
        "            return_offsets_mapping=True,\n",
        "        )\n",
        "\n",
        "        # Create DataLoader\n",
        "        dataset = TensorDataset(\n",
        "            tokenized['input_ids'], tokenized['attention_mask'], tokenized['offset_mapping']\n",
        "        )\n",
        "        dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "        self.model.eval()\n",
        "        results = []  # Store results for all sentences\n",
        "\n",
        "        for batch_index, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            offset_mapping = batch[2]\n",
        "            current_text = cleaned_sentences[batch_index]\n",
        "\n",
        "            # Compute embeddings and baseline embeddings\n",
        "            embeddings = self.model.roberta.embeddings.word_embeddings(input_ids).detach()\n",
        "            baseline_embeddings = self._baseline_zero_embed(input_ids, embeddings)\n",
        "\n",
        "            # Define forward pass for integrated gradients\n",
        "            def model_forward(inputs):\n",
        "                outputs = self.model.roberta(inputs_embeds=inputs, attention_mask=attention_mask)\n",
        "                logits = self.model.classifier(outputs.last_hidden_state)\n",
        "                return logits\n",
        "\n",
        "            # Compute attributions using integrated gradients\n",
        "            embeddings.requires_grad = True\n",
        "            ig = IntegratedGradients(model_forward)\n",
        "            attributions = ig.attribute(\n",
        "                inputs=embeddings,\n",
        "                baselines=baseline_embeddings,\n",
        "                internal_batch_size=128,\n",
        "                target=0,\n",
        "                n_steps=300,\n",
        "                return_convergence_delta=False,\n",
        "            )\n",
        "            attributions = attributions.sum(dim=2).squeeze(0).detach().cpu().numpy()\n",
        "            \n",
        "            #Clear CUDA cache\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            # Map RoBERTa tokens to SpaCy tokens and compute scores\n",
        "            token_results = self._spacy_map(\n",
        "                current_text, input_ids[0].cpu(), offset_mapping[0], attributions\n",
        "            )\n",
        "\n",
        "            # Compute agency and baseline scores\n",
        "            agency_score = self.model(\n",
        "                inputs_embeds=embeddings, attention_mask=attention_mask\n",
        "            )['logits'].detach().cpu().item()\n",
        "            baseline_score = self.model(\n",
        "                inputs_embeds=baseline_embeddings, attention_mask=attention_mask\n",
        "            )['logits'].detach().cpu().item()\n",
        "\n",
        "            token_results['agency'] = agency_score\n",
        "            token_results['baseline'] = baseline_score\n",
        "            results.append(token_results)\n",
        "\n",
        "        # Construct DataFrame\n",
        "        df = pd.DataFrame(\n",
        "            data={\n",
        "                'text': sentences,\n",
        "                'agency': [res['agency'] for res in results],\n",
        "                'baseline': [res['baseline'] for res in results],\n",
        "                'token': [res['tokens'] for res in results],\n",
        "                'attribution': [res['attributions'] for res in results],\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.df = df\n",
        "        return df\n",
        "\n",
        "    def _clean_sentences(self, sentences):\n",
        "        \"\"\"Clean and normalize input sentences.\"\"\"\n",
        "        return [ftfy.fix_text(re.sub(r\"\\s\\s+\", \" \", sent).strip()) for sent in sentences]\n",
        "\n",
        "    def _baseline_zero_embed(self, input_ids, embeddings):\n",
        "        \"\"\"Create baseline embeddings with zero values except for special tokens.\"\"\"\n",
        "        baseline = torch.zeros_like(embeddings).to(device)\n",
        "        for i, ids in enumerate(input_ids):\n",
        "            special_token_positions = [j for j, token_id in enumerate(ids) if token_id in [0, 2]]\n",
        "            for pos in special_token_positions:\n",
        "                baseline[i, pos, :] = embeddings[i, pos, :]\n",
        "        return baseline\n",
        "\n",
        "    def _spacy_map(self, text, token_ids, offsets, attributions):\n",
        "        \"\"\"Map RoBERTa tokens and attributions to SpaCy tokens.\"\"\"\n",
        "        roberta_tokens = self.tokenizer.convert_ids_to_tokens(token_ids.tolist())\n",
        "        filtered_tokens = [\n",
        "            (token.replace('Ġ', ''), attribution, offset)\n",
        "            for token, attribution, offset in zip(roberta_tokens, attributions, offsets)\n",
        "            if token not in ['<pad>', '<s>', '</s>']\n",
        "        ]\n",
        "        filtered_tokens, filtered_attributions, filtered_offsets = zip(*filtered_tokens)\n",
        "\n",
        "        doc = self.nlp(text)\n",
        "        spacy_tokens = [token.text for token in doc]\n",
        "        spacy_offsets = [(token.idx, token.idx + len(token.text)) for token in doc]\n",
        "\n",
        "        spacy_attributions = np.zeros(len(spacy_tokens))\n",
        "        spacy_index, roberta_index = 0, 0\n",
        "        while spacy_index < len(spacy_offsets) and roberta_index < len(filtered_offsets):\n",
        "            spacy_start, spacy_end = spacy_offsets[spacy_index]\n",
        "            roberta_start, roberta_end = filtered_offsets[roberta_index]\n",
        "            if spacy_start <= roberta_start < spacy_end:\n",
        "                spacy_attributions[spacy_index] += filtered_attributions[roberta_index]\n",
        "                if roberta_end <= spacy_end:\n",
        "                    roberta_index += 1\n",
        "                else:\n",
        "                    spacy_index += 1\n",
        "            elif roberta_start < spacy_start:\n",
        "                roberta_index += 1\n",
        "            else:\n",
        "                spacy_index += 1\n",
        "\n",
        "        return {\n",
        "            'tokens': spacy_tokens,\n",
        "            'attributions': spacy_attributions,\n",
        "            'f_tokens': np.array(filtered_tokens),\n",
        "            'f_attributions': np.array(filtered_attributions),\n",
        "        }\n",
        "\n",
        "    def render_ig(self, sentence_index, latex=False):\n",
        "        \"\"\"Render integrated gradients for a specific sentence in HTML or LaTeX.\"\"\"\n",
        "        row = self.df.iloc[sentence_index]\n",
        "        text, agency, tokens, attributions = (\n",
        "            row['text'], row['agency'], row['token'], row['attribution']\n",
        "        )\n",
        "        print(f\"index: {sentence_index}\\n\")\n",
        "        if latex:\n",
        "            display(self._display_tex(tokens, self._map_ag(attributions, agency, text)))\n",
        "        else:\n",
        "            display(self._display_html(tokens, self._map_ag(attributions, agency, text)))\n",
        "\n",
        "    def _map_ag(self, attributions, agency, text, show=False):\n",
        "        \"\"\"Map and normalize attributions with agency scores.\"\"\"\n",
        "        adjusted_attributions = attributions + (agency - attributions.sum()) / len(attributions)\n",
        "        adjusted_attributions = self._group_negations(text, adjusted_attributions, show=show)\n",
        "        if agency > 0:\n",
        "            adjusted_attributions = np.clip(adjusted_attributions, 0, 1)\n",
        "            return adjusted_attributions / adjusted_attributions.max() * agency\n",
        "        else:\n",
        "            adjusted_attributions = np.clip(adjusted_attributions, -1, 0)\n",
        "            return adjusted_attributions / adjusted_attributions.min() * agency\n",
        "\n",
        "    def _group_negations(self, text, attributions, show=False):\n",
        "        \"\"\"Group negations to adjust attributions.\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        for token in doc:\n",
        "            if token.dep_ == \"neg\":\n",
        "                related_tokens = [token.i, token.head.i]\n",
        "                for child in token.head.children:\n",
        "                    if child.dep_ in [\"acomp\", \"prt\"]:\n",
        "                        related_tokens.append(child.i)\n",
        "                if token.head.dep_ == 'auxpass':\n",
        "                    related_tokens.append(token.head.head.i)\n",
        "                if show:\n",
        "                    print(doc[related_tokens])\n",
        "                attributions[related_tokens] = attributions[related_tokens].sum()\n",
        "        return attributions\n",
        "\n",
        "    def _hlstr(self, string, color='white'):\n",
        "        \"\"\"Highlight a string with a background color.\"\"\"\n",
        "        return f\"<mark style=background-color:{color}>{string} </mark>\"\n",
        "\n",
        "    def _colorize(self, attrs, cmap='PiYG'):\n",
        "        \"\"\"Colorize attributions for visualization.\"\"\"\n",
        "        norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
        "        cmap = matplotlib.colormaps.get_cmap(cmap)\n",
        "        return list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
        "\n",
        "    def _display_html(self, tokens, attrs, scale_factor=1):\n",
        "        \"\"\"Display tokens with HTML highlighting.\"\"\"\n",
        "        return HTML(\n",
        "            \"\".join(map(self._hlstr, tokens, self._colorize(scale_factor * attrs)))\n",
        "        )\n",
        "\n",
        "    def _texstr(self, string, color='white'):\n",
        "        \"\"\"Render a string with a LaTeX colorbox.\"\"\"\n",
        "        tex_str = f\"\\\\colorbox[HTML]({color[1:]})({string})\"\n",
        "        return tex_str.replace('(', '{').replace(')', '}')\n",
        "\n",
        "    def _display_tex(self, tokens, attrs, scale_factor=1):\n",
        "        \"\"\"Display tokens with LaTeX highlighting.\"\"\"\n",
        "        return \" \".join(map(self._texstr, tokens, self._colorize(scale_factor * attrs)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i1mLGcYYUT5L"
      },
      "outputs": [],
      "source": [
        "# define your sentences\n",
        "sentences = [\"I'm nothing but the least not lazy person.\",\n",
        "              \"I'm not motivated.\",\n",
        "              \"I'm in no way motivated.\",\n",
        "              \"It is not true that I'm nothing but the least not lazy person.\",\n",
        "              \"I'm one of the least lazy people you'll ever meet.\",\n",
        "              'I have never been unmotivated!',\n",
        "              'These people are not lazy at all!']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "zNoh8iBxUUOr",
        "outputId": "4e17de94-526c-4164-c907-5cc605c5b15b"
      },
      "outputs": [],
      "source": [
        "# Instantiate an element for IG inspection\n",
        "ai = AgencyIG()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "514e7be639a647d8944f471950a56e21",
            "85ef6540e9ac47bea8f2be546d707658",
            "cb63f09d52234d5d9e064f363cfa51a0",
            "dc34e7fab5324d2f953e6be2427a1307",
            "4e03c5f8d8a94700a5ba53d65bfeee86",
            "880910408a7c41e3b07b814e64378935",
            "15b57597a7ac49fb832627e73b41cad2",
            "563d547f8f6e4274a40bc0eeacae5936",
            "c9c200f087614d3db41da3a3a3da046b",
            "ee86b7dbe67f4977a916e6b4116ede01",
            "31bd51ee982248a9bc881c2e04fadb1c"
          ]
        },
        "id": "OV8Q1ZToUWO-",
        "outputId": "31396e89-2f71-4d32-9651-149cbf1000ef"
      },
      "outputs": [],
      "source": [
        "# Extract IG attributions\n",
        "ai.extract_ig(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "FsaegFnWUsuK",
        "outputId": "1cafcc5c-cde7-42f7-e98d-2ccdec014ddf"
      },
      "outputs": [],
      "source": [
        "# Show the result\n",
        "for i in range(len(sentences)):\n",
        "    ai.render_ig(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "OdmvY5bNU_gB",
        "outputId": "a56655e8-cc40-4c81-e661-a3f559258abd"
      },
      "outputs": [],
      "source": [
        "# Show the result in LateX format\n",
        "for i in range(len(sentences)):\n",
        "    ai.render_ig(i,latex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ftLF1_PXyK-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15b57597a7ac49fb832627e73b41cad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31bd51ee982248a9bc881c2e04fadb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e03c5f8d8a94700a5ba53d65bfeee86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514e7be639a647d8944f471950a56e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85ef6540e9ac47bea8f2be546d707658",
              "IPY_MODEL_cb63f09d52234d5d9e064f363cfa51a0",
              "IPY_MODEL_dc34e7fab5324d2f953e6be2427a1307"
            ],
            "layout": "IPY_MODEL_4e03c5f8d8a94700a5ba53d65bfeee86"
          }
        },
        "563d547f8f6e4274a40bc0eeacae5936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ef6540e9ac47bea8f2be546d707658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880910408a7c41e3b07b814e64378935",
            "placeholder": "​",
            "style": "IPY_MODEL_15b57597a7ac49fb832627e73b41cad2",
            "value": "Evaluating:   0%"
          }
        },
        "880910408a7c41e3b07b814e64378935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c200f087614d3db41da3a3a3da046b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb63f09d52234d5d9e064f363cfa51a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563d547f8f6e4274a40bc0eeacae5936",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9c200f087614d3db41da3a3a3da046b",
            "value": 0
          }
        },
        "dc34e7fab5324d2f953e6be2427a1307": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee86b7dbe67f4977a916e6b4116ede01",
            "placeholder": "​",
            "style": "IPY_MODEL_31bd51ee982248a9bc881c2e04fadb1c",
            "value": " 0/7 [00:01&lt;?, ?it/s]"
          }
        },
        "ee86b7dbe67f4977a916e6b4116ede01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
